{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT based online question answerer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import *\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.8.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformers.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from googlesearch import search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import html\n",
    "import re\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import progressbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-large-uncased-whole-word-masking-finetuned-squad\")\n",
    "model = TFAutoModelForQuestionAnswering.from_pretrained(\"bert-large-uncased-whole-word-masking-finetuned-squad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''South Park is an American animated sitcom created by Trey Parker and Matt Stone \n",
    "and developed by Brian Graden for the Comedy Central television network. The series revolves \n",
    "around four boys—Stan Marsh, Kyle Broflovski, Eric Cartman, and Kenny McCormick—and their exploits\n",
    "in and around the titular Colorado town. The show became infamous for its profanity and dark, \n",
    "surreal humor that satirizes a wide range of topics towards a mature audience.'''\n",
    "# source: https://en.wikipedia.org/wiki/South_Park"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What is South Park?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is South Park?\n",
      "Answer: an american animated sitcom\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# src: https://huggingface.co/transformers/usage.html?highlight=question%20answering\n",
    "\n",
    "inputs = tokenizer.encode_plus(question, text, add_special_tokens=True, return_tensors=\"tf\")\n",
    "input_ids = inputs[\"input_ids\"].numpy()[0]\n",
    "\n",
    "text_tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
    "answer_start_scores, answer_end_scores = model(inputs)\n",
    "\n",
    "answer_start = tf.argmax(\n",
    "answer_start_scores, axis=1\n",
    ").numpy()[0]  # Get the most likely beginning of answer with the argmax of the score\n",
    "answer_end = (\n",
    "tf.argmax(answer_end_scores, axis=1) + 1\n",
    ").numpy()[0]  # Get the most likely end of answer with the argmax of the score\n",
    "answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(input_ids[answer_start:answer_end]))\n",
    "\n",
    "print(f\"Question: {question}\")\n",
    "print(f\"Answer: {answer}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(question, text):\n",
    "    inputs = tokenizer.encode_plus(question, text, add_special_tokens=True, return_tensors=\"tf\")\n",
    "    input_ids = inputs[\"input_ids\"].numpy()[0]\n",
    "\n",
    "    text_tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
    "    start_scores, end_scores = model(inputs)\n",
    "\n",
    "    start = tf.argmax( start_scores, axis=1 ).numpy()[0]\n",
    "    end = (tf.argmax(end_scores, axis=1) + 1 ).numpy()[0]\n",
    "    \n",
    "    answer = tokenizer.convert_tokens_to_string(\n",
    "                    tokenizer.convert_ids_to_tokens(input_ids[start:end])\n",
    "    )\n",
    "    start_score = tf.math.reduce_max(start_scores, axis=1).numpy()[0]\n",
    "    end_score = tf.math.reduce_max(end_scores, axis=1).numpy()[0]\n",
    "    \n",
    "    return start_score, end_score, answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask(question, results=1):\n",
    "    print(\"Searching the internet...\")\n",
    "    \n",
    "    urls = [uri for uri in  search(question, tld='com', lang='en', start=0, stop=5)]\n",
    "    text = []\n",
    "    scores = []\n",
    "\n",
    "    with progressbar.ProgressBar(max_value=10) as bar:\n",
    "        for i in range(len(urls)):\n",
    "            content = requests.get(urls[i]).text\n",
    "            paragraphs = html.fromstring(content).findall('.//p')\n",
    "            text += [re.sub(\"\\w*[^0-9a-zA-Z.,;' ]\\w*/g\", \"\", p.text_content()) \n",
    "                           for p in paragraphs if len(p.text_content())>100][:5]\n",
    "            bar.update(i)\n",
    "    print(\"Looking for an answer...\")        \n",
    "    \n",
    "    for p in text:\n",
    "        scores.append(get_score(question, p))\n",
    "    \n",
    "    ranked = sorted(scores ,key=lambda x: x[1], reverse=True)[:results] \n",
    "    answers = [ x[2] for x in ranked]\n",
    "    return answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching the internet...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (10 of 10) |########################| Elapsed Time: 0:00:00 Time:  0:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for an answer...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['an american animated television sitcom']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask(\"What is South Park?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
